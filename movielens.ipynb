{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6Na9FvSaI9Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CH0YYtbaI9a"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpspogh_aI9b"
      },
      "outputs": [],
      "source": [
        "df_links = pd.read_csv('links.csv')\n",
        "df_movies = pd.read_csv('movies.csv')\n",
        "df_ratings = pd.read_csv('ratings.csv')\n",
        "\n",
        "df_links, df_movies, df_ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2twbrse2aI9b"
      },
      "outputs": [],
      "source": [
        "df_tags = pd.read_csv('tags.csv')\n",
        "\n",
        "tags = np.unique(list(map(lambda x: x.lower(), df_tags.iloc[:, 2].tolist()))).tolist()\n",
        "tag_vocab = {tag: i for i, tag in enumerate(tags)}\n",
        "tag_itos = {i: tag for tag, i in tag_vocab.items()}\n",
        "\n",
        "print(\"unique tags:\", len(tags))\n",
        "\n",
        "df_tags.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH1Irf2QaI9c"
      },
      "outputs": [],
      "source": [
        "for genre_str in df_movies['genres']:\n",
        "    movie_genres = genre_str.split('|')\n",
        "    for g in [x.lower().replace(' ', '_') for x in movie_genres]:\n",
        "        if g not in df_movies.columns:\n",
        "            df_movies.insert(loc=len(df_movies.columns), column=g, value=0)\n",
        "\n",
        "for i in range(0, len(df_movies)):\n",
        "    for g in [x.lower().replace(' ', '_') for x in df_movies['genres'][i].split('|')]:\n",
        "        df_movies.at[i, g] = 1\n",
        "\n",
        "df_movies = df_movies.drop(columns=['(no_genres_listed)'])\n",
        "df_movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPKAuWb8aI9c"
      },
      "outputs": [],
      "source": [
        "df_ratings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg5xrs2SaI9d"
      },
      "outputs": [],
      "source": [
        "class MovielensDataset(Dataset):\n",
        "    def __init__(self, df_ratings):\n",
        "        self.df_ratings = df_ratings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_ratings)\n",
        "    \n",
        "    def __getitem__(self, idx):        \n",
        "        user_id = self.df_ratings.iloc[idx, 0]\n",
        "        movie_id = self.df_ratings.iloc[idx, 1] \n",
        "        rating = self.df_ratings.iloc[idx, 2]\n",
        "        \n",
        "        return user_id, movie_id, rating\n",
        "    \n",
        "movielens_dataset = MovielensDataset(df_ratings)\n",
        "movielens_dataset[0], len(movielens_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "wpwZGF7GDTiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUkOfbCDaI9d"
      },
      "source": [
        "# Classic matrix factorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vrkb7AUtaI9e"
      },
      "outputs": [],
      "source": [
        "class MatrixFactorizationModel(torch.nn.Module):\n",
        "    def __init__(self, num_users, num_movies, num_factors):\n",
        "        super().__init__()\n",
        "        self.user_embeddings = torch.nn.Embedding(num_users, num_factors)\n",
        "        self.movie_embeddings = torch.nn.Embedding(num_movies, num_factors)\n",
        "\n",
        "        # initialize embeddings so that the output activations are roughly 2.5 (mean of dataset)\n",
        "        #\n",
        "        # (x / 2)**2*num_factors = 2.5\n",
        "        # (x / 2)**2 = 2.5 / num_factors\n",
        "        # x / 2 = math.sqrt(2.5 / num_factors)\n",
        "        # x = math.sqrt(2.5 / num_factors) * 2\n",
        "        self.user_embeddings.weight.data.uniform_(0, math.sqrt(2.5 / num_factors) * 2)\n",
        "        self.movie_embeddings.weight.data.uniform_(0, math.sqrt(2.5 / num_factors) * 2)\n",
        "\n",
        "    def forward(self, user_id, movie_id):\n",
        "        user_embedding = self.user_embeddings(user_id)\n",
        "        movie_embedding = self.movie_embeddings(movie_id)\n",
        "        \n",
        "        return (user_embedding * movie_embedding).sum(dim=-1)\n",
        "\n",
        "\n",
        "n_users = df_ratings['userId'].max() + 1\n",
        "n_movies = df_ratings['movieId'].max() + 1\n",
        "model = MatrixFactorizationModel(n_users, n_movies, 50)\n",
        "\n",
        "t = torch.tensor(1).unsqueeze(0)\n",
        "print(\"mean of embeddings: \", model.user_embeddings.weight.data.mean().item())\n",
        "print(\"mean of dot product: \", (model.user_embeddings(t) * model.movie_embeddings(t)).mean(dim=-1).item())\n",
        "print(\"mean of output: \", (model.user_embeddings(t) * model.movie_embeddings(t)).sum(dim=-1).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eir2PK49aI9f"
      },
      "outputs": [],
      "source": [
        "split = int(len(movielens_dataset) * 0.8)\n",
        "train_data, valid_data = torch.utils.data.random_split(movielens_dataset, [split, len(movielens_dataset) - split], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(valid_data, batch_size=64, shuffle=True, num_workers=0)\n",
        "\n",
        "model = MatrixFactorizationModel(n_users, n_movies, 50)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "lr = 3e-4\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "def train():\n",
        "    losses = []\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        model.train()\n",
        "        user_ids, movie_ids, ratings = batch\n",
        "        y_hat = model(user_ids.to(device), movie_ids.to(device)).squeeze()\n",
        "        loss = F.mse_loss(y_hat, ratings.float().to(device))\n",
        "        loss.backward()\n",
        "        losses.append(loss.item())\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    return np.mean(losses)\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate():\n",
        "    losses = []\n",
        "    for i, batch in enumerate(valid_loader):\n",
        "        model.eval()\n",
        "        user_ids, movie_ids, ratings = batch\n",
        "        y_hat = model(user_ids.to(device), movie_ids.to(device)).squeeze()\n",
        "        loss = F.mse_loss(y_hat, ratings.float().to(device))\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    return np.mean(losses)\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for e in range(5):\n",
        "    train_loss.append(train())\n",
        "    valid_loss.append(validate())\n",
        "    print(f'Epoch {e}, train loss: {train_loss[-1]}, valid loss: {valid_loss[-1]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  plt.plot(train_loss)\n",
        "  plt.plot(valid_loss)\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ASGmkRnQcFe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NitYqFhjaI9g"
      },
      "outputs": [],
      "source": [
        "movies = df_movies[:50]['movieId'].tolist()\n",
        "titles = df_movies[:50]['title'].tolist()\n",
        "\n",
        "movie_embeddings = model.movie_embeddings(torch.tensor(movies).to(device)).detach().cpu()\n",
        "t = torch.pca_lowrank(movie_embeddings, q=2)\n",
        "\n",
        "X = t[0][:, 0]\n",
        "Y = t[0][:, 1]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(18.5, 10.5)\n",
        "ax.scatter(X, Y)\n",
        "\n",
        "for i, title in enumerate(titles):\n",
        "    ax.annotate(title, (X[i], Y[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Collaborative Model"
      ],
      "metadata": {
        "id": "6U-aFyOKYrrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.fill(torch.randn(1, 19), 0.1)\n",
        "b = torch.fill(torch.randn(1, 100), 2.5)\n",
        "\n",
        "print(torch.cat((a, b), dim=-1).mean())"
      ],
      "metadata": {
        "id": "o5YYTg0JzvWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepCollaborativeFilteringModel(torch.nn.Module):\n",
        "    def __init__(self, num_users, num_movies, num_factors):\n",
        "        super().__init__()\n",
        "        self.user_embeddings = torch.nn.Embedding(num_users, num_factors)\n",
        "        self.movie_embeddings = torch.nn.Embedding(num_movies, num_factors)\n",
        "        self.ffnn = torch.nn.Sequential(\n",
        "            torch.nn.Linear(num_factors * 2, num_factors),\n",
        "            torch.nn.Dropout(p=0.2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(num_factors, 1),\n",
        "        )\n",
        "\n",
        "\n",
        "        for p in self.ffnn.parameters():\n",
        "          if p.dim() > 1:\n",
        "            torch.nn.init.kaiming_uniform_(p, nonlinearity=\"relu\")\n",
        "\n",
        "    def forward(self, user_id, movie_id):\n",
        "        user_embedding = self.user_embeddings(user_id)\n",
        "        movie_embedding = self.movie_embeddings(movie_id)\n",
        "        x = torch.cat((user_embedding, movie_embedding), dim=-1)\n",
        "        x = self.ffnn(x)\n",
        "        return torch.sigmoid(x) * 5.5\n",
        "\n",
        "model = DeepCollaborativeFilteringModel(n_users, n_movies, 50)\n",
        "print(\"Mean: \", model(torch.ones(64, dtype=int), torch.ones(64, dtype=int)).mean().item())"
      ],
      "metadata": {
        "id": "nn-ZrMTRX_Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Add a forward hook to the model\n",
        "#\n",
        "activation = {}\n",
        "\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "layers = [module for module in model.modules() if not isinstance(module, torch.nn.ReLU)]\n",
        "\n",
        "for l in layers:\n",
        "    l.register_forward_hook(get_activation(l))\n",
        "\n",
        "# perform a forward pass\n",
        "model(torch.arange(128).unsqueeze(0), torch.arange(128).unsqueeze(0))\n",
        "\n",
        "#\n",
        "# visualize histograms\n",
        "#\n",
        "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
        "legends = []\n",
        "for i, key in enumerate(activation): # note: exclude the output layer\n",
        "  t = activation[key]\n",
        "  print('layer %d (%10s): mean %+.2f, std %.2f, saturated: %.2f%%' % (i, key, t.mean(), t.std(), (t.abs() > 0.97).float().mean()*100))\n",
        "  hy, hx = torch.histogram(t, density=True)\n",
        "  plt.plot(hx[:-1].detach(), hy.detach())\n",
        "  legends.append(f'layer {i} ({key}')\n",
        "plt.legend(legends);\n",
        "plt.title('activation distribution')"
      ],
      "metadata": {
        "id": "UE-eTsINZheX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "qxBpYT3g80kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(len(movielens_dataset) * 0.8)\n",
        "train_data, valid_data = torch.utils.data.random_split(movielens_dataset, [split, len(movielens_dataset) - split], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(valid_data, batch_size=128, shuffle=True, num_workers=0)\n",
        "\n",
        "n_users = df_ratings['userId'].max() + 1\n",
        "n_movies = df_ratings['movieId'].max() + 1\n",
        "model = DeepCollaborativeFilteringModel(n_users, n_movies, 100)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "lr = 3e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "def train():\n",
        "    losses = []\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        model.train()\n",
        "        user_ids, movie_ids, ratings = batch\n",
        "        y = ratings.float().to(device) #((ratings * 2) - 1).to(torch.int64).to(device)\n",
        "        y_hat = model(user_ids.to(device), movie_ids.to(device)).squeeze()\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        loss.backward()\n",
        "        losses.append(loss.item())\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    return np.mean(losses)\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate():\n",
        "    losses = []\n",
        "    for i, batch in enumerate(valid_loader):\n",
        "        model.eval()\n",
        "        user_ids, movie_ids, ratings = batch\n",
        "        y = ratings.float().to(device) # ((ratings * 2) - 1).to(torch.int64).to(device)\n",
        "        y_hat = model(user_ids.to(device), movie_ids.to(device)).squeeze()\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    return np.mean(losses)\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for e in range(5):\n",
        "    train_loss.append(train())\n",
        "    valid_loss.append(validate())\n",
        "    print(f'Epoch {e}, train loss: {train_loss[-1]}, valid loss: {valid_loss[-1]}')"
      ],
      "metadata": {
        "id": "taWwE3OYY3R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTWOUYtHaI9h"
      },
      "source": [
        "# Concatenating features and embeddings\n",
        "\n",
        "Building on the model from https://arxiv.org/abs/1606.07792, now using other features such as category.\n",
        "\n",
        "<img src=\"https://github.com/Klingefjord/notebooks/blob/main/wide_n_deep.png?raw=1\" height=\"400\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqaBxU8uaI9h"
      },
      "outputs": [],
      "source": [
        "df_movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROzzoeTKaI9i"
      },
      "outputs": [],
      "source": [
        "class MovielensCategoriesDataset(Dataset):\n",
        "    def __init__(self, df_ratings, df_movies):\n",
        "        self.df_ratings = df_ratings\n",
        "        self.df_movies = df_movies\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_ratings)\n",
        "    \n",
        "    def __getitem__(self, idx):        \n",
        "        user_id = self.df_ratings.iloc[idx, 0]\n",
        "        movie_id = self.df_ratings.iloc[idx, 1] \n",
        "        rating = self.df_ratings.iloc[idx, 2]\n",
        "        categories = self.df_movies.loc[self.df_movies['movieId'] == movie_id].iloc[:, 3:].values\n",
        "        categories = torch.tensor(categories[0].tolist())        \n",
        "        return user_id, movie_id, float(rating), categories\n",
        "    \n",
        "categories_dataset = MovielensCategoriesDataset(df_ratings, df_movies)\n",
        "categories_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = torch.nn.Sequential(\n",
        "    torch.nn.Linear(119, 50),\n",
        "    torch.nn.Linear(50, 1)\n",
        ")\n",
        "\n",
        "print(test(torch.randn(119)).mean(), test(torch.randn(119)).std())"
      ],
      "metadata": {
        "id": "uLNhdZhMEAeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdSFpRAcaI9i"
      },
      "outputs": [],
      "source": [
        "class MovielensCategoriesModel(torch.nn.Module):\n",
        "    def __init__(self, num_users, num_movies, num_factors, num_categories):\n",
        "        super().__init__()\n",
        "        self.user_embeddings = torch.nn.Embedding(num_users, num_factors)\n",
        "        self.movie_embeddings = torch.nn.Embedding(num_movies, num_factors)\n",
        "        \n",
        "        self.ffnn = torch.nn.Sequential(\n",
        "            torch.nn.Linear(num_factors * 2, out_features=num_factors),\n",
        "            torch.nn.Dropout(p=0.2),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(num_factors, 1)\n",
        "        )\n",
        "\n",
        "        for p in self.ffnn.parameters():\n",
        "          if p.dim() > 1:\n",
        "            torch.nn.init.kaiming_uniform_(p, nonlinearity=\"relu\")\n",
        "\n",
        "    # concat the embeddings with the categories vector \n",
        "    # and feed the result through a simple FFNN.\n",
        "    def forward(self, user_id, movie_id, categories):\n",
        "        user_embedding = self.user_embeddings(user_id)\n",
        "        movie_embedding = self.movie_embeddings(movie_id)\n",
        "        x = torch.cat([(user_embedding * movie_embedding), categories], dim=-1)\n",
        "        x = self.ffnn(x)\n",
        "        return torch.sigmoid(x) * 5.5\n",
        "\n",
        "model = MovielensCategoriesModel(n_users, n_movies, 100, 19)\n",
        "y_hat = model(torch.arange(128), torch.arange(128), torch.zeros(128, 19).unsqueeze(0))\n",
        "y_hat.mean().item(), y_hat.std().item()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0,0,1,1]), dim=0)"
      ],
      "metadata": {
        "id": "pkt8PhMqoIsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Add a forward hook to the model\n",
        "#\n",
        "activation = {}\n",
        "\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "model = MovielensCategoriesModel(n_users, n_movies, 50, 19)\n",
        "model.eval()\n",
        "\n",
        "layers = [module for module in model.modules() if not isinstance(module, torch.nn.ReLU)]\n",
        "\n",
        "for l in layers:\n",
        "    l.register_forward_hook(get_activation(l))\n",
        "\n",
        "# perform a forward pass\n",
        "model(torch.arange(256), torch.arange(256), torch.randn(256, 19))\n",
        "\n",
        "#\n",
        "# visualize histograms\n",
        "#\n",
        "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
        "legends = []\n",
        "for i, key in enumerate(activation): # note: exclude the output layer\n",
        "  t = activation[key]\n",
        "  print('layer %d (%10s): mean %+.2f, std %.2f, saturated: %.2f%%' % (i, key, t.mean(), t.std(), (t.abs() > 0.97).float().mean()*100))\n",
        "  hy, hx = torch.histogram(t, density=True)\n",
        "  plt.plot(hx[:-1].detach(), hy.detach())\n",
        "  legends.append(f'layer {i} ({key}')\n",
        "plt.legend(legends);\n",
        "plt.title('activation distribution')"
      ],
      "metadata": {
        "id": "KfsnqPH98RYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ayq6qXQBaI9i"
      },
      "outputs": [],
      "source": [
        "torch.Generator().manual_seed(42)\n",
        "\n",
        "split = int(len(categories_dataset) * 0.8)\n",
        "train_data, valid_data = torch.utils.data.random_split(categories_dataset, [split, len(movielens_dataset) - split])\n",
        "\n",
        "#train_data = torch.utils.data.Subset(train_data, torch.arange(100))\n",
        "#valid_data = torch.utils.data.Subset(valid_data, torch.arange(80))\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(valid_data, batch_size=128, shuffle=True, num_workers=0)\n",
        "\n",
        "n_users = df_ratings['userId'].max() + 1\n",
        "n_movies = df_ratings['movieId'].max() + 1\n",
        "model = MovielensCategoriesModel(n_users, n_movies, 100, 19)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "lr = 3e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "\n",
        "\n",
        "def train():\n",
        "    losses = []\n",
        "\n",
        "    for batch in train_loader:\n",
        "        model.train()\n",
        "        user_ids, movie_ids, ratings, categories = batch\n",
        "        y_hat = model(user_ids.to(device), movie_ids.to(device), categories.to(device)).squeeze()\n",
        "        loss = F.mse_loss(y_hat, ratings.float().to(device))\n",
        "        loss.backward()\n",
        "        losses.append(loss.item())\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return np.mean(losses)\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate():\n",
        "    losses = []\n",
        "    for batch in valid_loader:\n",
        "        model.eval()\n",
        "        user_ids, movie_ids, ratings, categories = batch\n",
        "        y_hat = model(user_ids.to(device), movie_ids.to(device), categories.to(device)).squeeze()\n",
        "        loss = F.mse_loss(y_hat, ratings.float().to(device))\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    return np.mean(losses)\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for e in range(5):\n",
        "    train_loss.append(train())\n",
        "    valid_loss.append(validate())\n",
        "    print(f'Epoch {e}, train loss: {train_loss[-1]}, valid loss: {valid_loss[-1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_nTBj1CaI9j"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_loss)\n",
        "plt.plot(valid_loss)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBck3YAuaI9j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit ('3.10.7')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b6c9e77d69fdc734b0a4e50053fe601397809ac29df62e5af5373f8044db8c53"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}