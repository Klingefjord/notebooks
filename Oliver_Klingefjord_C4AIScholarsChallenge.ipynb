{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Klingefjord/notebooks/blob/main/Oliver_Klingefjord_C4AIScholarsChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRUrAHlZKdWd"
      },
      "source": [
        "# C4AI Scholars Program Takehome Challenge\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY4wvFv6lTbY"
      },
      "source": [
        "### Background\n",
        "\n",
        "Welcome to the C4AI Scholars Program Take-Home Challenge! This exercise is designed to allow you to showcase your engineering and problem solving skills. The Challenge consists of three parts:\n",
        "\n",
        "* Part One of the challenge requires identifying bugs, and getting the code working. This is designed to test your ability to grapple with real world engineering challenges.\n",
        "* Part Two of the challenge tests your ability to generate code for a specified problem. \n",
        "* Part Three of the challenge is an opportunity for you to attempt an optional challenge question that extends the original problem set. \n",
        "\n",
        "\n",
        "These tasks were chosen as a setting to see how you think about problems, even if they are not in your own research field of interest. The tasks and dataset are not meant to be indicative of the research goals of the Scholar Program. We purposefully have selected a simple toy problem so the focus is on how you think, and does not require significant machine learning resources. \n",
        "\n",
        "Good luck! If you have questions about the framing of the questions, please contact info@for.ai  \n",
        "\n",
        "\n",
        "### How to Use and Submit this Document\n",
        "\n",
        "* **Make a copy of this document** and **rename** it **Firstname_Lastname_C4AIScholarsChallenge**\n",
        "* Once you’ve completed all tasks, **save and pin your revisions**\n",
        "* **Submit a link** to your final document via the [Cohere For AI Scholars Program application](https://jobs.lever.co/cohere/?department=Cohere%20For%20AI). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmbPmOHhLx4U"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc-enDOhazoe"
      },
      "source": [
        "## Overview of Singular Value Decomposition\n",
        "\n",
        "In this takehome, you will be working on a problem involving singular value decomposition. Singular Value Decomposition (SVD) exists for every rectangular matrix. The nice thing about SVD is that the original matrix can be expressed as the sum of outer products of left and singular vectors scaled by the corresponding singular values. Formally:\n",
        "\n",
        "> Let 𝛢 be a rectangular matrix of dimensions 𝑚𝘹𝑛, then the SVD of the matrix A is given by $ A = U𝛴V^T$ where $U$ is an orthogonal matrix of shape mxm containing the left singular vectors, $V$ is an orthogonal matrix of shape nxn containing the right singular vectors and $𝛴$ is a diagonal matrix containing the singular values of $A$. This formulation of SVD can be re-expressed as \\begin{align} A = \\sum_{i=1}^{r} s_i. u_i v_i^T \\end{align} where $r = \\text{min}(m,n)$ represents the rank of the matrix, $s_i$ is the $i$th singular value and $u_i v_i^T$ is the outer product of the $i$th left and right singular vectors. \n",
        "\n",
        "<!-- \\begin{align}\n",
        "A = \\sum_{i=1}^{\\text{min}(m,n)} s_i. u_i v_i^T\n",
        "\\end{align}\n",
        "\\begin{align} -->\n",
        "\n",
        "> The singular values $𝛴$ are decreasing in order. So, each outer product is scaled by a smaller value as we compute each term in the sum above. This gives us an opportunity to approximate $A$ using only the sum of the first $k$ outer products where $k < \\text{min}(m,n)$ $-$ this effectively means that we are zero-ing out some of the singular values by assuming that the contribution to the sum is negligible. This is called low-rank approximation.\n",
        "\n",
        "If you aren't familiar with singular value decomposition, or the above feels rusty, don't worry. Take a moment to brush up your knowledge using any of the following resources:\n",
        "* [stanford lecture notes on low rank approximations](https://web.stanford.edu/class/cs168/l/l9.pdf)\n",
        "* [youtube series of short and beginner friendly lectures](https://www.youtube.com/watch?v=gXbThCXjZFM&list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcL7u9wJjPF3"
      },
      "source": [
        "## Check for understanding (3 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v-iHTH3nasL"
      },
      "source": [
        "#### Q1: What are some real world applications of low rank approximations?\n",
        "\n",
        "\n",
        "#### Answer: Compressing big matrices like images to only include essential features, denoising matrix data, reconstructing matrix data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHGqpn3tkFRL"
      },
      "source": [
        "#### Q2: What are the benefits of compressing a deep neural network? How would you measure the benefits of compression?\n",
        "\n",
        "\n",
        "#### Answer: The benefits are faster inference and smaller model size. The benefits of compression could be measured as a function of the test loss or accuracy and the FLOPs required to run the model. We want as big of a reduction in FLOPs as possible for as little reduction in accuracy as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9r4v5vng9ma"
      },
      "source": [
        "#### Q3: In this takehome, we will consider how singular value decomposition can be used to compress a deep neural network. Compared to other compression methods used for deep neural networks such as pruning, quantization, or efficient architectures, what are the relative merits/demerits of low rank approximations? Choose one or two alternative compression methods and compare with singular value decomposition.\n",
        "\n",
        "#### Answer: Quantization is a technique that clips the 32-bit floating point values of the parameters in a network to 8-bit integers. This reduces the cost of inference significantly at the expense of some precision accuracy. Compared to low-rank factorization, no heed is paid to the relative importance of the parameters – you cannot conditionally clip certain parameters to integers, whereas low-rank matrix factorization only filters out parameters that are of low relative importance. Another drawback is that backpropagation becomes infeasible due to it being impossible to calculate the gradients with discrete values. In the case of low-rank approximations, this is not the case. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O81HH6D3Lugd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoWy4-iQIYJ0"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBFa6wXqAKgK",
        "outputId": "731d86ec-3beb-47d7-fae0-dca38501c27a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-haiku in /usr/local/lib/python3.7/dist-packages (0.0.8)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.21.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.8.10)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.3.0)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.0.2)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.5)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.23)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.22+cuda11.cudnn805)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.7)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (0.8.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (3.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (5.10.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dm-haiku optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wzdlf_milUbR"
      },
      "outputs": [],
      "source": [
        "from typing import Iterator, Mapping, Tuple\n",
        "from copy import deepcopy\n",
        "import time\n",
        "from absl import app\n",
        "import haiku as hk\n",
        "import matplotlib.pyplot as plt\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from functools import partial\n",
        "import math\n",
        "\n",
        "Batch = Tuple[np.ndarray, np.ndarray]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsYJmUqz-uFT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjTGxEfqnSmd"
      },
      "source": [
        "## Coding Challenge Part I : Debugging Challenge (10 Points)\n",
        "\n",
        "\n",
        "We are now going to explore using SVD to compute low rank approximations of the parameters of a small deep neural network. You are using a very simple toy model as a first baseline. Section 3 will give you the chance to improve baseline accuracy beyond this very simple model -- this is just a toy setting to first explore low rank approximations.\n",
        "\n",
        "The first part of this challenge is primarily a debugging challenge. It will require removing bugs in order to train a very simple network. We have introduced several bugs -- some are subtle and will not break your code but will degrade final performance. These subtle bugs are introduced to understand your grasp of fundamental machine learning principles. There are also more obvious bugs designed to break your code. \n",
        "\n",
        "* [**4 points**] Your goal is to get the code working. There are 4 bugs in the code, all 4 of these are subtle bugs which are designed to impair test accuracy but not break the code. You will get partial points for each of the 4 bugs you find. After finding all bugs, your test performance should be around 66-67% test accuracy. \n",
        "\n",
        "* [**2 points**] We will give extra points for also adding improved documentation to each of the functions we introduce in this section, and for describing the fixes to the bugs. \n",
        "\n",
        "* [**4 points**] There are also two functions you will need to code up in this section -- we indicate where these code changes need to happen with TODO comments. \n",
        "\n",
        "* Do not alter the model architecture or the learning rate.\n",
        "\n",
        "\n",
        "Useful tips:\n",
        "* To iterate faster and avoid training for 10000 steps each time you want to test whether you have found all the bugs, a good sign you have caught the bugs is wheter after 1000/10000 steps your accuracy >40%.\n",
        "* The colab difftool is useful to track what code you have changed during the debugging challenge (incase you need to revert code). You can access this via tools > diff notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IqpgWQJs-evw"
      },
      "outputs": [],
      "source": [
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR10_STD = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "\n",
        "def net_fn(batch: Batch) -> jnp.ndarray:\n",
        "  x = normalize(batch[0])\n",
        "  \n",
        "  # Do NOT alter the architecture definition below.\n",
        "  net = hk.Sequential([\n",
        "      hk.Conv2D(output_channels=6*3, kernel_shape=(5,5)),\n",
        "      jax.nn.relu,\n",
        "      hk.AvgPool(window_shape=(2,2), strides=(2,2), padding='VALID'),\n",
        "      jax.nn.relu,\n",
        "      hk.Conv2D(output_channels=16*3, kernel_shape=(5,5)),\n",
        "      jax.nn.relu,\n",
        "      hk.AvgPool(window_shape=(2,2), strides=(2,2), padding='VALID'),\n",
        "      hk.Flatten(),\n",
        "      hk.Linear(3000), jax.nn.relu,\n",
        "      hk.Linear(2000), jax.nn.relu,\n",
        "      hk.Linear(2000), jax.nn.relu,\n",
        "      hk.Linear(1000), jax.nn.relu,\n",
        "      hk.Linear(10),\n",
        "  ])\n",
        "  return net(x)\n",
        "\n",
        "def load_dataset(\n",
        "    split: str,\n",
        "    *,\n",
        "    is_training: bool,\n",
        "    batch_size: int,\n",
        ") -> Iterator[tuple]:\n",
        "  \"\"\"Loads the dataset as a generator of batches.\"\"\"\n",
        "  ds = tfds.load('cifar10', split=split, as_supervised=True).cache().repeat()\n",
        "  if is_training:\n",
        "    ds = ds.shuffle(10 * batch_size, seed=0)\n",
        "  ds = ds.batch(batch_size)\n",
        "  return iter(tfds.as_numpy(ds))\n",
        "\n",
        "def compute_loss(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
        "  \"\"\"Compute the loss of the network, including L2 regression.\"\"\"\n",
        "  x, y = batch\n",
        "  logits = net.apply(params, batch)\n",
        "  labels = jax.nn.one_hot(y, 10)\n",
        "\n",
        "  l2_reg = 0.5 * sum(\n",
        "        jnp.sum(jnp.square(p)) for p in jax.tree_util.tree_leaves(params))\n",
        "  nll = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
        "  return nll + 1e-4 * l2_reg\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def compute_accuracy(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
        "  _, y = batch\n",
        "  logits = net.apply(params, batch)\n",
        "  predictions = jnp.argmax(logits, axis=-1)\n",
        "  return jnp.mean(predictions == y)\n",
        "\n",
        "@jax.jit\n",
        "def update(\n",
        "    params: hk.Params,\n",
        "    opt_state: optax.OptState,\n",
        "    batch: Batch,\n",
        ") -> Tuple[hk.Params, optax.OptState]:\n",
        "  grads = jax.grad(compute_loss)(params, batch)\n",
        "  updates, opt_state = opt.update(grads, opt_state)\n",
        "  new_params = optax.apply_updates(params, updates)\n",
        "  return new_params, opt_state\n",
        "\n",
        "@jax.jit\n",
        "def ema_update(params, avg_params):\n",
        "  return optax.incremental_update(params, avg_params, step_size=0.001)\n",
        "\n",
        "\n",
        "def normalize(images):\n",
        "  mean = np.asarray(CIFAR10_MEAN)\n",
        "  std = np.asarray(CIFAR10_STD)\n",
        "  x = images.astype(jnp.float32) / 255.\n",
        "  return (x - mean) / std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5iI930cIjzM"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4-HuMSH_Cbw",
        "outputId": "cacf3ccf-9c07-4229-a78c-8c9870967d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 0] Validation / Test accuracy: 0.103 / 0.103.\n"
          ]
        }
      ],
      "source": [
        "net = hk.without_apply_rng(hk.transform(net_fn))\n",
        "\n",
        "# Do not change learning rate\n",
        "opt = optax.adam(1e-3)\n",
        "\n",
        "train = load_dataset(\"train[80%:]\", is_training=True, batch_size=1000)\n",
        "validation = load_dataset(\"train[0%:80%]\", is_training=False, batch_size=10000)\n",
        "test = load_dataset(\"test\", is_training=False, batch_size=10000)\n",
        "\n",
        "params = avg_params = net.init(jax.random.PRNGKey(42), next(train))\n",
        "opt_state = opt.init(params)\n",
        "\n",
        "# Do not alter the number of steps\n",
        "for step in range(1):\n",
        "  if step % 1000 == 0:\n",
        "    val_accuracy = compute_accuracy(avg_params, next(validation))\n",
        "    test_accuracy = compute_accuracy(avg_params, next(test))\n",
        "    val_accuracy, test_accuracy = jax.device_get(\n",
        "        (val_accuracy, test_accuracy))\n",
        "    print(f\"[Step {step}] Validation / Test accuracy: \"\n",
        "          f\"{val_accuracy:.3f} / {test_accuracy:.3f}.\")\n",
        "\n",
        "  params, opt_state = update(params, opt_state, next(train))\n",
        "  avg_params = ema_update(params, avg_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBWQhbV-MPQA"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQmOspeD0jCh"
      },
      "source": [
        "## Coding Challenge Part 2: Compression through Low Rank Approximation (8 points)\n",
        "\n",
        "In this section, you will add code to compute the low rank approximation and to compute evaluation metrics. We will evaluate whether the low rank approximation allows for speed up in inference time. We define inference time as the average time to compute the prediction for all examples in the test set.\n",
        "\n",
        "* [**4 points**] You will need to add code to define both the compute_eval_metrics and rank_approximated weight function. \n",
        "* [**4 points**] Q4 and Q5 are worth 2 points each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sdZqO7W_KSX8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def compute_eval_metrics(params, batch, n_samples):\n",
        "  duration_list = []\n",
        "  accuracy_list = []\n",
        "  for _ in range(n_samples):\n",
        "    start = time.time()\n",
        "    acc = compute_accuracy(params, batch)\n",
        "    duration = time.time() - start\n",
        "    duration_list.append(duration)\n",
        "    accuracy_list.append(acc)\n",
        "\n",
        "  return accuracy_list, duration_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "X8U8Nlp9IS4q"
      },
      "outputs": [],
      "source": [
        "def rank_approximated_weight(weight: jnp.ndarray, rank_fraction: float):\n",
        "  # TODO: replace the code below with code to compute the SVD of the matrix to return the rank approximated weights u and v for a given matrix.\n",
        "  u, s, v = jnp.linalg.svd(weight, full_matrices=False, compute_uv=True)\n",
        "\n",
        "  rank = int((len(s) * rank_fraction).round())\n",
        "\n",
        "  print(rank)\n",
        "\n",
        "  u = u.at[:, :rank].set(0.0)\n",
        "  v = v.at[:, :rank].set(0.0)\n",
        "\n",
        "  return u, v.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvm9InR4JG4F"
      },
      "source": [
        "### Evaluations at different ranks\n",
        "\n",
        "The code below first replaces the weights with the low rank factorizations at different rank fractions. For each modified net, we compute the new eval accuracy. Firstly, add code for the rank_approximated_weight and add code to correctly compute the time for inference (the duration)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "id": "PEjLxaDPEGEY",
        "outputId": "c02e27cb-24a9-4688-bd2e-6ed960f320fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model at 1.0\n",
            "3000\n",
            "2000\n",
            "2000\n",
            "1000\n",
            "10\n",
            "Rank Fraction / Test accuracy: 1.00 / 0.100.\n",
            "Rank Fraction / Duration: 1.00 / 0.0730.\n",
            "Evaluating the model at 0.9\n",
            "2700\n",
            "1800\n",
            "1800\n",
            "900\n",
            "9\n",
            "Rank Fraction / Test accuracy: 0.90 / 0.100.\n",
            "Rank Fraction / Duration: 0.90 / 0.0858.\n",
            "Evaluating the model at 0.8\n",
            "2400\n",
            "1600\n",
            "1600\n",
            "800\n",
            "8\n",
            "Rank Fraction / Test accuracy: 0.80 / 0.100.\n",
            "Rank Fraction / Duration: 0.80 / 0.0867.\n",
            "Evaluating the model at 0.7000000000000001\n",
            "2100\n",
            "1400\n",
            "1400\n",
            "700\n",
            "7\n",
            "Rank Fraction / Test accuracy: 0.70 / 0.110.\n",
            "Rank Fraction / Duration: 0.70 / 0.0872.\n",
            "Evaluating the model at 0.6000000000000001\n",
            "1800\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-ab67e50f1f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# TODO: complete coding the rank_approximated_weight function to compute the SVD of the matrix to return the rank approximated weights u and v for a given matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank_approximated_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_fraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mrank_truncated_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-4bdca6998850>\u001b[0m in \u001b[0;36mrank_approximated_weight\u001b[0;34m(weight, rank_fraction)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrank_approximated_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_fraction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# TODO: replace the code below with code to compute the SVD of the matrix to return the rank approximated weights u and v for a given matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_uv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrank_fraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "rank_truncated_params = deepcopy(params)\n",
        "ranks_and_accuracies = []\n",
        "ranks_and_times = []\n",
        "for rank_fraction in np.arange(1.0, 0.0, -0.1):\n",
        "\n",
        "  print(f\"Evaluating the model at {rank_fraction}\")\n",
        "  for layer in params.keys():\n",
        "    if 'conv' in layer:\n",
        "      continue\n",
        "    weight = params[layer]['w']\n",
        "    # TODO: complete coding the rank_approximated_weight function to compute the SVD of the matrix to return the rank approximated weights u and v for a given matrix.\n",
        "    u, v = rank_approximated_weight(weight, rank_fraction)\n",
        "    rank_truncated_params[layer]['w'] = u@v\n",
        "\n",
        "  test_batch = next(test)\n",
        "  # we compute metrics over 50 samples to reduce noise in the measurement.\n",
        "  n_samples = 50\n",
        "  # TODO: complete coding the compute_eval_metrics function to compute latency 50 seperate times given the batch passed to compute_eval_metrics. Return the average across all latencies you store.\n",
        "  test_accuracy, latency = compute_eval_metrics(rank_truncated_params, next(test), n_samples)\n",
        "  print(f\"Rank Fraction / Test accuracy: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(test_accuracy):.3f}.\")\n",
        "  ranks_and_accuracies.append((rank_fraction, np.mean(test_accuracy)))\n",
        "  print(f\"Rank Fraction / Duration: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(latency):.4f}.\")\n",
        "  ranks_and_times.append((rank_fraction, np.mean(latency)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzyvqIr38eWw"
      },
      "source": [
        "### Q4: What do you observe as the relationship between rank fraction and test accuracy?\n",
        "\n",
        "Plot this relationship showing accuracy (y-axis) vs rank percentage of the matrix (x-axis). You should use the ranks_and_accuracies list computed above.\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranks_and_accuracies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi8_ZvUmCxWc",
        "outputId": "855abee1-f27b-4919-9fe2-f311cc502534"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1.0, 0.1083),\n",
              " (0.9, 0.105),\n",
              " (0.8, 0.099999994),\n",
              " (0.7000000000000001, 0.099999994),\n",
              " (0.6000000000000001, 0.099999994),\n",
              " (0.5000000000000001, 0.099999994),\n",
              " (0.40000000000000013, 0.099999994),\n",
              " (0.30000000000000016, 0.099999994),\n",
              " (0.20000000000000018, 0.099999994),\n",
              " (0.1000000000000002, 0.099999994)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "TCdYJ6lSEKM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "f86938ef-4e85-4e72-b59a-36968e3cb334"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "## TODO: add your code below to plot the relationship between time and test set accuracy\n",
        "ranks = [x[0] for x in ranks_and_accuracies]\n",
        "accs  = [x[1] for x in ranks_and_accuracies]\n",
        "plt.plot(ranks, accs)\n",
        "plt.xlabel(\"rank factor\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRkI8rAO5UYe"
      },
      "source": [
        "### Q5: Does replacing the weight matrix with the low factor matrix result in latency speed ups?\n",
        "\n",
        "Plot the relationship of time (y-axis) vs rank percentage (x-axis). To do so add code to compute the ranks_and_times list.\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "f7jlMYxhi7E-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "7a2d24ce-269a-4638-f2f6-b6a693dd73ae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ranks = [x[0] for x in ranks_and_times]\n",
        "times = [x[1] * 1000 for x in ranks_and_times]\n",
        "plt.plot(ranks, times)\n",
        "plt.xlabel(\"rank factor\")\n",
        "plt.ylabel(\"time (ms)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR3JTDWb2QII"
      },
      "source": [
        "## Coding Challenge Part 3: Perform evaluations on the dataset in factorized space. (4 points)\n",
        "\n",
        "In this section, you will perform evaluations on the dataset in factorized space.\n",
        "\n",
        "* [**4 points**] 2 pts for question 6 and question 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "OctdUxerSZut"
      },
      "outputs": [],
      "source": [
        "def low_rank_net_fn(batch: Batch, rank: float) -> jnp.ndarray:\n",
        "  \n",
        "  x = normalize(batch[0])\n",
        "  total_input_dim = np.prod(x.shape[1:])\n",
        "\n",
        "  # Do not alter the architecture code.\n",
        "  net = hk.Sequential([\n",
        "      hk.Conv2D(output_channels=6*3, kernel_shape=(5,5)),\n",
        "      jax.nn.relu,\n",
        "      hk.AvgPool(window_shape=(2,2), strides=(2,2), padding='VALID'),\n",
        "      jax.nn.relu,\n",
        "      hk.Conv2D(output_channels=16*3, kernel_shape=(5,5)),\n",
        "      jax.nn.relu,\n",
        "      hk.AvgPool(window_shape=(2,2), strides=(2,2), padding='VALID'),\n",
        "      hk.Flatten(),\n",
        "      hk.Linear(int(rank * min(total_input_dim, 3000)), with_bias=False),\n",
        "      hk.Linear(3000), jax.nn.relu,\n",
        "      hk.Linear(int(rank * 2000), with_bias=False), \n",
        "      hk.Linear(2000), jax.nn.relu,\n",
        "      hk.Linear(int(rank * 2000), with_bias=False), \n",
        "      hk.Linear(2000), jax.nn.relu,      \n",
        "      hk.Linear(int(rank * 1000), with_bias=False), \n",
        "      hk.Linear(1000), jax.nn.relu,\n",
        "      hk.Linear(int(rank * 10), with_bias=False),\n",
        "      hk.Linear(10),\n",
        "  ])\n",
        "  return net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "Zi2TN_WV-jgZ",
        "outputId": "c04f67b3-8328-4a2a-fa3e-526c2f53c443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/haiku/_src/base.py:515: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  param = init(shape, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the model at 1.00\n",
            "Rank Fraction / Test accuracy: 1.00 / 0.108.\n",
            "Rank Fraction / Duration: 1.00 / 0.2429.\n",
            "Evaluating the model at 0.90\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-9663321945c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank_approximated_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_fraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mlow_rank_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvanilla_to_low_rank_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mlow_rank_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvanilla_to_low_rank_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-09c549e62d34>\u001b[0m in \u001b[0;36mrank_approximated_weight\u001b[0;34m(weight, rank_fraction)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrank_approximated_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_fraction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# TODO: replace the code below with code to compute the SVD of the matrix to return the rank approximated weights u and v for a given matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_uv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mrank_fraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "vanilla_to_low_rank_map = {\n",
        "    'conv2_d': 'conv2_d',\n",
        "    'conv2_d_1': 'conv2_d_1',\n",
        "    'linear': ['linear', 'linear_1'],\n",
        "    'linear_1': ['linear_2', 'linear_3'],\n",
        "    'linear_2': ['linear_4', 'linear_5'],\n",
        "    'linear_3': ['linear_6', 'linear_7'],\n",
        "    'linear_4': ['linear_8', 'linear_9']\n",
        "}\n",
        "\n",
        "\n",
        "ranks_and_accuracies = []\n",
        "ranks_and_times = []\n",
        "for rank_fraction in np.arange(1.0, 0.0, -0.1):\n",
        "  low_rank_net_fn_partial = partial(low_rank_net_fn, rank=rank_fraction)\n",
        "  net = hk.without_apply_rng(hk.transform(low_rank_net_fn_partial)) \n",
        "  low_rank_params = net.init(jax.random.PRNGKey(42), next(train))\n",
        "\n",
        "  print(f\"Evaluating the model at {rank_fraction:.2f}\")\n",
        "\n",
        "  for layer in vanilla_to_low_rank_map.keys():\n",
        "    if 'conv' in layer:\n",
        "      low_rank_params[layer] = params[layer]\n",
        "      continue\n",
        "    weight = params[layer]['w']\n",
        "    u, v = rank_approximated_weight(weight, rank_fraction)\n",
        "    low_rank_params[vanilla_to_low_rank_map[layer][0]]['w'] = u\n",
        "    low_rank_params[vanilla_to_low_rank_map[layer][1]]['w'] = v\n",
        "    low_rank_params[vanilla_to_low_rank_map[layer][1]]['b'] = params[layer]['b']\n",
        "  \n",
        "  test_accuracy, duration = compute_eval_metrics(low_rank_params, next(test), 50)\n",
        "  ranks_and_times.append((rank_fraction, np.mean(duration)))\n",
        "  ranks_and_accuracies.append((rank_fraction, np.mean(test_accuracy)))\n",
        "  print(f\"Rank Fraction / Test accuracy: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(test_accuracy):.3f}.\")\n",
        "  print(f\"Rank Fraction / Duration: \"\n",
        "          f\"{rank_fraction:.2f} / {np.mean(duration):.4f}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObBn-Pf_996r"
      },
      "source": [
        "### Q6: Plot a curve showing time vs rank percentage of the matrix "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0bJJFL4LM7q"
      },
      "outputs": [],
      "source": [
        "# TODO: add code to plot the relationship between time vs percentage rank of the matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "313ALwDu93k1"
      },
      "source": [
        "### Q7: What do you observe between time and the percentage rank of the matrix.\n",
        "\n",
        "### Put your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHcBKkogM6uV"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEAu9Vu-0rWX"
      },
      "source": [
        "## Coding Challenge Part 4: Take this Further (10 bonus points)\n",
        "\n",
        "This part of the challenge is designed to be open ended. If you wanted to show some more skills, here is your chance to shine. We include two options below -- **only do one of the options**:\n",
        "\n",
        "**Option 1:** Implement a change that isn't SVD but minimizes inference latency while preserving accuracy. Can you outperform SVD? \n",
        "\n",
        "\n",
        "\n",
        "**Option 2:** Improve the quality of code for this takehome. Pretend you are reviewing a peer and add comments to cells with suggestions of how to improve the code quality. Try and make your comments action orientated and precise. \n",
        "\n",
        "\n",
        "**For Option 1, DO NOT alter the previous code sections, instead add any new code below. You should not need to add new code for Option 2, instead just add comments to cells.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoN-IhY9hNQE"
      },
      "outputs": [],
      "source": [
        "# TODO: add code for option 1 here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq2zcXoRNkYx"
      },
      "source": [
        "## You have made it to the end of the challenge!\n",
        "\n",
        "Before you submit your completed challenge document, please make sure to **save and pin your revisions** before submitting a link to your submission via the [Cohere For AI Scholars Program Application.](https://jobs.lever.co/cohere/) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-v-iHTH3nasL",
        "UHGqpn3tkFRL"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}